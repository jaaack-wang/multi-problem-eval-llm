{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "from scripts.llm import get_num_of_tokens, get_completion\n",
    "from scripts.utils import save_obj_as_pickle, read_obj_from_pickle\n",
    "from scripts.data import make_database, make_prompts_for_clf\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Premise: a matador in white and gold clothing and pink sock is getting hit by a raging bull\\nHypothesis: The angry bull is attacking the matador a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entailment</td>\n",
       "      <td>Premise: A man wearing a black sweater and a knit cap sits in front of mountain scenery , with a cloudy sky overhead .\\nHypothesis: A man is outdo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entailment</td>\n",
       "      <td>Premise: Two men are making hand gestures and posing for a picture .\\nHypothesis: Two men are ready to have their picture taken .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entailment</td>\n",
       "      <td>Premise: Workers are removing ice from a walkway .\\nHypothesis: Workers outside on a slippery walkway\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entailment</td>\n",
       "      <td>Premise: A man riding a motorcycle on a dirt road passing several junk or abandoned cars on the side of the road .\\nHypothesis: A man is riding a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  \\\n",
       "0     Neutral   \n",
       "1  Entailment   \n",
       "2  Entailment   \n",
       "3  Entailment   \n",
       "4  Entailment   \n",
       "\n",
       "                                                                                                                                                    text  \n",
       "0  Premise: a matador in white and gold clothing and pink sock is getting hit by a raging bull\\nHypothesis: The angry bull is attacking the matador a...  \n",
       "1  Premise: A man wearing a black sweater and a knit cap sits in front of mountain scenery , with a cloudy sky overhead .\\nHypothesis: A man is outdo...  \n",
       "2                    Premise: Two men are making hand gestures and posing for a picture .\\nHypothesis: Two men are ready to have their picture taken .\\n  \n",
       "3                                                Premise: Workers are removing ice from a walkway .\\nHypothesis: Workers outside on a slippery walkway\\n  \n",
       "4  Premise: A man riding a motorcycle on a dirt road passing several junk or abandoned cars on the side of the road .\\nHypothesis: A man is riding a ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# both sets have 10,000 text pairs, which is too large. \n",
    "def loadData(fp, sample_size=1000):\n",
    "    df = pd.read_table(fp, header=1, names=[\"label\", \"premise\", \"hypothesis\"])\n",
    "    df = df[df.label != \"-\"]\n",
    "    df = df.sample(sample_size, random_state=234)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.label = df.label.apply(str.capitalize)\n",
    "    df[\"text\"] = \"Premise: \" + df.premise + \"\\nHypothesis: \" + df.hypothesis + \"\\n\"\n",
    "    df = df[['label', 'text']]\n",
    "    return df\n",
    "\n",
    "clf_task = \"SNLI\"\n",
    "test_fp = f\"data/raw/text classification/{clf_task}/test.txt\"\n",
    "test_df = loadData(test_fp)\n",
    "\n",
    "dev_fp = f\"data/raw/text classification/{clf_task}/dev.txt\"\n",
    "dev_df = loadData(dev_fp)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entailment       351\n",
       "Neutral          338\n",
       "Contradiction    311\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       31.753000\n",
       "std         7.934037\n",
       "min        16.000000\n",
       "25%        26.000000\n",
       "50%        31.000000\n",
       "75%        36.000000\n",
       "max        70.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.text.apply(get_num_of_tokens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral          362\n",
       "Entailment       333\n",
       "Contradiction    305\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       31.996000\n",
       "std         8.556939\n",
       "min        15.000000\n",
       "25%        26.000000\n",
       "50%        30.000000\n",
       "75%        37.000000\n",
       "max        75.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.text.apply(get_num_of_tokens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database\n",
    "\n",
    "Sources for the prompt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_instance', 'max_instance_size', 'labels', 'testData', 'testInstances', 'devData', 'devInstances'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = make_database(test_df, dev_df, num_instance=500, max_instance_size=500)\n",
    "database.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database[\"promptTemplates\"] = dict()\n",
    "database[\"promptTemplates\"][\"zero-shot\"] = dict()\n",
    "\n",
    "\n",
    "single_clf = \"Given the following premise and hypothesis, determine the inference relation between them. \" \\\n",
    "             \"Respond with 'Entailment' if the hypothesis logically follows from the premise, \" \\\n",
    "             \"'Contradiction' if they are in direct opposition, and 'Neutral' if neither applies. \\n\\n\" \\\n",
    "             \"$text\\nInference relation:\"\n",
    "\n",
    "batch_clf = \"Given the following $num pairs of premises and hypotheses, determine the inference relation for each pair line by line. \" \\\n",
    "            \"Respond with 'Entailment' if the hypothesis entails the premise, and 'Contradiction' if they contradict. \" \\\n",
    "            \"If neither is the case, respond with 'Neutral.' Provide your answers line by line.\\n\\n\" \\\n",
    "            \"$texts\\nInference relations for the $num text pairs provided above:\\n\"\n",
    "\n",
    "index_selection_one_cat_a_time = \"Go over the $num text pairs below and list the index numbers of the text pairs where \" \\\n",
    "                                 \"the inference relation between the premise and the hypothesis is $relationship according to the following instructions:\\n\" \\\n",
    "                                 \"If none of the text pairs contain $relationship inference relation, write 'None.'\\n\" \\\n",
    "                                 \"If all text pairs contain $relationship inference relation, write 'All.'\\n\" \\\n",
    "                                 \"Otherwise, provide the index numbers of the text pairs where the inference relation between the premise \" \\\n",
    "                                 \"and the hypothesis is $relationship, each on a separate line.\\n\\n\" \\\n",
    "                                 \"Here are the text pairs:\\n\\n$texts\\n'None,' 'All,' or the index numbers of the text pairs where the inference relation \" \\\n",
    "                                 \"between the premise and the hypothesis is $relationship:\\n\"\n",
    "\n",
    "index_selection_all_cat_at_once = \"Go over the $num text pairs below. \" \\\n",
    "                                  \"First, list the index numbers of the text pairs that contain entailment inference relation. \" \\\n",
    "                                  \"Then, select all text pairs that contain contradiction inference relation. \" \\\n",
    "                                  \"Finally, select all text pairs that contain neutral inference relation.\\n\" \\\n",
    "                                  \"If none of the text pairs satisfy a condition, write 'None.'\\n\" \\\n",
    "                                  \"If all the text pairs belong satisfy a condition, write 'All.'\\n\" \\\n",
    "                                  \"Otherwise, provide the index numbers of the text pairs that satisfy each condition.\\n\\n\" \\\n",
    "                                  \"Here are the text pairs:\\n\\n$texts\\n\" \\\n",
    "                                  \"Output your responses in JSON format with three keys: 'entailment', 'contradiction', and 'neutral'.\" \\\n",
    "                                  \"\\nA formatted example output is provided below.\\n\" \\\n",
    "                                  \"{'entailment': [None/All or index numbers of text pairs that contain entailment inference relation], \" \\\n",
    "                                  \"'contradiction': [None/All or index numbers of text pairs that contain contradiction inference relation], \" \\\n",
    "                                  \"'neutral': [None/All or index numbers of text pairs that contain neutral inference relation]}\"\n",
    "\n",
    "index_selection_all_cat_at_once_adjusted =  \"Go over the $num text pairs below. \" \\\n",
    "                                            \"First, list the index numbers of the text pairs that contain entailment inference relation. \" \\\n",
    "                                            \"Then, select all text pairs that contain contradiction inference relation. \" \\\n",
    "                                            \"Finally, select all text pairs that contain neutral inference relation.\\n\" \\\n",
    "                                            \"If none of the text pairs satisfy a condition, write 'None.'\\n\" \\\n",
    "                                            \"If all the text pairs belong satisfy a condition, write 'All.'\\n\" \\\n",
    "                                            \"Otherwise, provide the index numbers of the text pairs that satisfy each condition.\\n\\n\" \\\n",
    "                                            \"Output your responses in JSON format with three keys: 'entailment', 'contradiction', and 'neutral'.\" \\\n",
    "                                            \"\\nA formatted example output is provided below.\\n\" \\\n",
    "                                            \"{'entailment': [None/All or index numbers of text pairs that contain entailment inference relation], \" \\\n",
    "                                            \"'contradiction': [None/All or index numbers of text pairs that contain contradiction inference relation], \" \\\n",
    "                                            \"'neutral': [None/All or index numbers of text pairs that contain neutral inference relation]}\\n\\n\" \\\n",
    "                                            \"Here are the text pairs:\\n\\n$texts\\n\" \\\n",
    "                                            \"JSON output:\\n\"\n",
    "                                            \n",
    "tasks = [\"single_clf\", \"batch_clf\", \"index_selection_one_cat_a_time\", \n",
    "         \"index_selection_all_cat_at_once\", \"index_selection_all_cat_at_once_adjusted\"]\n",
    "promptTemplates = [single_clf, batch_clf, index_selection_one_cat_a_time, \n",
    "                   index_selection_all_cat_at_once, index_selection_all_cat_at_once_adjusted]\n",
    "\n",
    "for task, tmp in zip(tasks, promptTemplates):\n",
    "    database[\"promptTemplates\"][\"zero-shot\"][task] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved object to data/databases/text classification/SNLI.pkl\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"data/databases/text classification/\", exist_ok=True)\n",
    "save_obj_as_pickle(database, f\"data/databases/text classification/{clf_task}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Prompts\n",
    "\n",
    "- The main purpose is to check if LLMs can output the desired formats given the prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = []\n",
    "num_instance = 2\n",
    "taskSizes = [3, 5]\n",
    "for propmtMode in [\"zero-shot\"]:\n",
    "    for task in tasks:\n",
    "        if task == \"single_clf\":\n",
    "            dev.append(make_prompts_for_clf(database, task, \"dev\", propmtMode)[:num_instance])\n",
    "            continue\n",
    "\n",
    "        for taskSize in taskSizes:  \n",
    "            dev.append(make_prompts_for_clf(database, task, \"dev\", propmtMode, taskSize, attr=\"relationship\", \n",
    "                                            label_attr_converter=None, num_instance=num_instance))\n",
    "\n",
    "dev = pd.concat(dev).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following premise and hypothesis, determine the inference relation between them. Respond with 'Entailment' if the hypothesis logically follows from the premise, 'Contradiction' if they are in direct opposition, and 'Neutral' if neither applies. \n",
      "\n",
      "Premise: A man wearing blue jeans and a black shirt is talking to a man wearing white shorts while they are sitting outside in folding chairs on a patio .\n",
      "Hypothesis: the men are inside the church\n",
      "\n",
      "Inference relation:\n",
      "--------------------------------------------------\n",
      "\n",
      "Given the following 3 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if the hypothesis entails the premise, and 'Contradiction' if they contradict. If neither is the case, respond with 'Neutral.' Provide your answers line by line.\n",
      "\n",
      "1. Premise: A man dressed all in white throws the first pitch at a baseball game .\n",
      "Hypothesis: A Senator starts a baseball game .\n",
      "\n",
      "2. Premise: A woman with dark hair and a red dress sits next to a little girl with blond-hair and a white dress while reading a book .\n",
      "Hypothesis: A tall person with hair\n",
      "\n",
      "3. Premise: A firefighter , in full uniform , looks off into the distance .\n",
      "Hypothesis: The firefighter is going to put out a fire .\n",
      "\n",
      "Inference relations for the 3 text pairs provided above:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is contradiction according to the following instructions:\n",
      "If none of the text pairs contain contradiction inference relation, write 'None.'\n",
      "If all text pairs contain contradiction inference relation, write 'All.'\n",
      "Otherwise, provide the index numbers of the text pairs where the inference relation between the premise and the hypothesis is contradiction, each on a separate line.\n",
      "\n",
      "Here are the text pairs:\n",
      "\n",
      "1. Premise: A man dressed all in white throws the first pitch at a baseball game .\n",
      "Hypothesis: A Senator starts a baseball game .\n",
      "\n",
      "2. Premise: A woman with dark hair and a red dress sits next to a little girl with blond-hair and a white dress while reading a book .\n",
      "Hypothesis: A tall person with hair\n",
      "\n",
      "3. Premise: A firefighter , in full uniform , looks off into the distance .\n",
      "Hypothesis: The firefighter is going to put out a fire .\n",
      "\n",
      "'None,' 'All,' or the index numbers of the text pairs where the inference relation between the premise and the hypothesis is contradiction:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is entailment according to the following instructions:\n",
      "If none of the text pairs contain entailment inference relation, write 'None.'\n",
      "If all text pairs contain entailment inference relation, write 'All.'\n",
      "Otherwise, provide the index numbers of the text pairs where the inference relation between the premise and the hypothesis is entailment, each on a separate line.\n",
      "\n",
      "Here are the text pairs:\n",
      "\n",
      "1. Premise: A man dressed all in white throws the first pitch at a baseball game .\n",
      "Hypothesis: A Senator starts a baseball game .\n",
      "\n",
      "2. Premise: A woman with dark hair and a red dress sits next to a little girl with blond-hair and a white dress while reading a book .\n",
      "Hypothesis: A tall person with hair\n",
      "\n",
      "3. Premise: A firefighter , in full uniform , looks off into the distance .\n",
      "Hypothesis: The firefighter is going to put out a fire .\n",
      "\n",
      "'None,' 'All,' or the index numbers of the text pairs where the inference relation between the premise and the hypothesis is entailment:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is neutral according to the following instructions:\n",
      "If none of the text pairs contain neutral inference relation, write 'None.'\n",
      "If all text pairs contain neutral inference relation, write 'All.'\n",
      "Otherwise, provide the index numbers of the text pairs where the inference relation between the premise and the hypothesis is neutral, each on a separate line.\n",
      "\n",
      "Here are the text pairs:\n",
      "\n",
      "1. Premise: A man dressed all in white throws the first pitch at a baseball game .\n",
      "Hypothesis: A Senator starts a baseball game .\n",
      "\n",
      "2. Premise: A woman with dark hair and a red dress sits next to a little girl with blond-hair and a white dress while reading a book .\n",
      "Hypothesis: A tall person with hair\n",
      "\n",
      "3. Premise: A firefighter , in full uniform , looks off into the distance .\n",
      "Hypothesis: The firefighter is going to put out a fire .\n",
      "\n",
      "'None,' 'All,' or the index numbers of the text pairs where the inference relation between the premise and the hypothesis is neutral:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text pairs that contain contradiction inference relation. Finally, select all text pairs that contain neutral inference relation.\n",
      "If none of the text pairs satisfy a condition, write 'None.'\n",
      "If all the text pairs belong satisfy a condition, write 'All.'\n",
      "Otherwise, provide the index numbers of the text pairs that satisfy each condition.\n",
      "\n",
      "Here are the text pairs:\n",
      "\n",
      "1. Premise: A man dressed all in white throws the first pitch at a baseball game .\n",
      "Hypothesis: A Senator starts a baseball game .\n",
      "\n",
      "2. Premise: A woman with dark hair and a red dress sits next to a little girl with blond-hair and a white dress while reading a book .\n",
      "Hypothesis: A tall person with hair\n",
      "\n",
      "3. Premise: A firefighter , in full uniform , looks off into the distance .\n",
      "Hypothesis: The firefighter is going to put out a fire .\n",
      "\n",
      "Output your responses in JSON format with three keys: 'entailment', 'contradiction', and 'neutral'.\n",
      "A formatted example output is provided below.\n",
      "{'entailment': [None/All or index numbers of text pairs that contain entailment inference relation], 'contradiction': [None/All or index numbers of text pairs that contain contradiction inference relation], 'neutral': [None/All or index numbers of text pairs that contain neutral inference relation]}\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in dev[(dev[\"taskSize\"] <= 3) & (dev[\"taskIndex\"] == 1)].prompt:\n",
    "    print(p)\n",
    "    print(\"-\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskIndex</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>targetLabel</th>\n",
       "      <th>task</th>\n",
       "      <th>#shot</th>\n",
       "      <th>CoT</th>\n",
       "      <th>taskSize</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Given the following premise and hypothesis, determine the inference relation between them. Respond with 'Entailment' if the hypothesis logically f...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>NA</td>\n",
       "      <td>single_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Given the following premise and hypothesis, determine the inference relation between them. Respond with 'Entailment' if the hypothesis logically f...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>NA</td>\n",
       "      <td>single_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Given the following 3 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...</td>\n",
       "      <td>[Neutral, Neutral, Neutral]</td>\n",
       "      <td>NA</td>\n",
       "      <td>batch_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1. Neutral\\n2. Neutral\\n3. Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Given the following 3 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...</td>\n",
       "      <td>[Neutral, Neutral, Neutral]</td>\n",
       "      <td>NA</td>\n",
       "      <td>batch_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1. Neutral\\n2. Neutral\\n3. Contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Given the following 5 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...</td>\n",
       "      <td>[Neutral, Neutral, Neutral, Entailment, Neutral]</td>\n",
       "      <td>NA</td>\n",
       "      <td>batch_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1. Neutral\\n2. Neutral\\n3. Neutral\\n4. Entailment\\n5. Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Given the following 5 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...</td>\n",
       "      <td>[Neutral, Neutral, Neutral, Entailment, Entailment]</td>\n",
       "      <td>NA</td>\n",
       "      <td>batch_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1. Neutral\\n2. Neutral\\n3. Neutral\\n4. Entailment\\n5. Entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{None}</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{None}</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{All}</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{None}</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{None}</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{All}</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{None}</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{4}</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{1, 2, 3, 5}</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{None}</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{4, 5}</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>None.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': {'None'}, 'entailment': {'None'}, 'neutral': {'All'}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        2\\n    ],\\n    \"neutral\": [\\n        1\\n    ]\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': {'None'}, 'entailment': {'None'}, 'neutral': {'All'}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        1\\n    ],\\n    \"neutral\": [\\n        2\\n    ]\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': {'None'}, 'entailment': {4}, 'neutral': {1, 2, 3, 5}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>{\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        2\\n    ],\\n    \"neutral\": [\\n        1,\\n        4,\\n        5\\n    ]\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': {'None'}, 'entailment': {4, 5}, 'neutral': {1, 2, 3}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>{\\n    \"entailment\": [\\n        4\\n    ],\\n    \"contradiction\": [\\n        1\\n    ],\\n    \"neutral\": [\\n        2,\\n        3,\\n        5\\n    ]\\n}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    taskIndex  \\\n",
       "0           1   \n",
       "1           2   \n",
       "2           1   \n",
       "3           2   \n",
       "4           1   \n",
       "5           2   \n",
       "6           1   \n",
       "7           1   \n",
       "8           1   \n",
       "9           2   \n",
       "10          2   \n",
       "11          2   \n",
       "12          1   \n",
       "13          1   \n",
       "14          1   \n",
       "15          2   \n",
       "16          2   \n",
       "17          2   \n",
       "18          1   \n",
       "19          2   \n",
       "20          1   \n",
       "21          2   \n",
       "\n",
       "                                                                                                                                                   prompt  \\\n",
       "0   Given the following premise and hypothesis, determine the inference relation between them. Respond with 'Entailment' if the hypothesis logically f...   \n",
       "1   Given the following premise and hypothesis, determine the inference relation between them. Respond with 'Entailment' if the hypothesis logically f...   \n",
       "2   Given the following 3 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...   \n",
       "3   Given the following 3 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...   \n",
       "4   Given the following 5 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...   \n",
       "5   Given the following 5 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...   \n",
       "6   Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "7   Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "8   Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "9   Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "10  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "11  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "12  Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "13  Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "14  Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "15  Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "16  Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "17  Go over the 5 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "18  Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "19  Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "20  Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "21  Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "\n",
       "                                                                     answer  \\\n",
       "0                                                             Contradiction   \n",
       "1                                                                Entailment   \n",
       "2                                               [Neutral, Neutral, Neutral]   \n",
       "3                                               [Neutral, Neutral, Neutral]   \n",
       "4                          [Neutral, Neutral, Neutral, Entailment, Neutral]   \n",
       "5                       [Neutral, Neutral, Neutral, Entailment, Entailment]   \n",
       "6                                                                    {None}   \n",
       "7                                                                    {None}   \n",
       "8                                                                     {All}   \n",
       "9                                                                    {None}   \n",
       "10                                                                   {None}   \n",
       "11                                                                    {All}   \n",
       "12                                                                   {None}   \n",
       "13                                                                      {4}   \n",
       "14                                                             {1, 2, 3, 5}   \n",
       "15                                                                   {None}   \n",
       "16                                                                   {4, 5}   \n",
       "17                                                                {1, 2, 3}   \n",
       "18  {'contradiction': {'None'}, 'entailment': {'None'}, 'neutral': {'All'}}   \n",
       "19  {'contradiction': {'None'}, 'entailment': {'None'}, 'neutral': {'All'}}   \n",
       "20  {'contradiction': {'None'}, 'entailment': {4}, 'neutral': {1, 2, 3, 5}}   \n",
       "21  {'contradiction': {'None'}, 'entailment': {4, 5}, 'neutral': {1, 2, 3}}   \n",
       "\n",
       "      targetLabel                             task  #shot    CoT  taskSize  \\\n",
       "0              NA                       single_clf      0  False         1   \n",
       "1              NA                       single_clf      0  False         1   \n",
       "2              NA                        batch_clf      0  False         3   \n",
       "3              NA                        batch_clf      0  False         3   \n",
       "4              NA                        batch_clf      0  False         5   \n",
       "5              NA                        batch_clf      0  False         5   \n",
       "6   Contradiction   index_selection_one_cat_a_time      0  False         3   \n",
       "7      Entailment   index_selection_one_cat_a_time      0  False         3   \n",
       "8         Neutral   index_selection_one_cat_a_time      0  False         3   \n",
       "9   Contradiction   index_selection_one_cat_a_time      0  False         3   \n",
       "10     Entailment   index_selection_one_cat_a_time      0  False         3   \n",
       "11        Neutral   index_selection_one_cat_a_time      0  False         3   \n",
       "12  Contradiction   index_selection_one_cat_a_time      0  False         5   \n",
       "13     Entailment   index_selection_one_cat_a_time      0  False         5   \n",
       "14        Neutral   index_selection_one_cat_a_time      0  False         5   \n",
       "15  Contradiction   index_selection_one_cat_a_time      0  False         5   \n",
       "16     Entailment   index_selection_one_cat_a_time      0  False         5   \n",
       "17        Neutral   index_selection_one_cat_a_time      0  False         5   \n",
       "18             NA  index_selection_all_cat_at_once      0  False         3   \n",
       "19             NA  index_selection_all_cat_at_once      0  False         3   \n",
       "20             NA  index_selection_all_cat_at_once      0  False         5   \n",
       "21             NA  index_selection_all_cat_at_once      0  False         5   \n",
       "\n",
       "                                                                                                                                                  preds  \n",
       "0                                                                                                                                               Neutral  \n",
       "1                                                                                                                                            Entailment  \n",
       "2                                                                                                                    1. Neutral\\n2. Neutral\\n3. Neutral  \n",
       "3                                                                                                              1. Neutral\\n2. Neutral\\n3. Contradiction  \n",
       "4                                                                                         1. Neutral\\n2. Neutral\\n3. Neutral\\n4. Entailment\\n5. Neutral  \n",
       "5                                                                                      1. Neutral\\n2. Neutral\\n3. Neutral\\n4. Entailment\\n5. Entailment  \n",
       "6                                                                                                                                                 None.  \n",
       "7                                                                                                                                                 None.  \n",
       "8                                                                                                                                                 None.  \n",
       "9                                                                                                                                                 None.  \n",
       "10                                                                                                                                                None.  \n",
       "11                                                                                                                                                None.  \n",
       "12                                                                                                                                                None.  \n",
       "13                                                                                                                                                None.  \n",
       "14                                                                                                                                                None.  \n",
       "15                                                                                                                                                None.  \n",
       "16                                                                                                                                                None.  \n",
       "17                                                                                                                                                None.  \n",
       "18                          {\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        2\\n    ],\\n    \"neutral\": [\\n        1\\n    ]\\n}  \n",
       "19                          {\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        1\\n    ],\\n    \"neutral\": [\\n        2\\n    ]\\n}  \n",
       "20  {\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        2\\n    ],\\n    \"neutral\": [\\n        1,\\n        4,\\n        5\\n    ]\\n}  \n",
       "21  {\\n    \"entailment\": [\\n        4\\n    ],\\n    \"contradiction\": [\\n        1\\n    ],\\n    \"neutral\": [\\n        2,\\n        3,\\n        5\\n    ]\\n}  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[\"preds\"] = dev.prompt.apply(get_completion)\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = []\n",
    "num_instance = 2\n",
    "\n",
    "taskSizes = [3, 5]\n",
    "for propmtMode in [\"zero-shot\"]:\n",
    "    for task in tasks[-1:]:\n",
    "        if task == \"single_clf\":\n",
    "            dev.append(make_prompts_for_clf(database, task, \"dev\", propmtMode)[:num_instance])\n",
    "            continue\n",
    "\n",
    "        for taskSize in taskSizes:  \n",
    "            dev.append(make_prompts_for_clf(database, task, \"dev\", propmtMode, taskSize, attr=\"relationship\", \n",
    "                                            label_attr_converter=None, num_instance=num_instance))\n",
    "\n",
    "dev = pd.concat(dev).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text pairs that contain contradiction inference relation. Finally, select all text pairs that contain neutral inference relation.\n",
      "If none of the text pairs satisfy a condition, write 'None.'\n",
      "If all the text pairs belong satisfy a condition, write 'All.'\n",
      "Otherwise, provide the index numbers of the text pairs that satisfy each condition.\n",
      "\n",
      "Output your responses in JSON format with three keys: 'entailment', 'contradiction', and 'neutral'.\n",
      "A formatted example output is provided below.\n",
      "{'entailment': [None/All or index numbers of text pairs that contain entailment inference relation], 'contradiction': [None/All or index numbers of text pairs that contain contradiction inference relation], 'neutral': [None/All or index numbers of text pairs that contain neutral inference relation]}\n",
      "\n",
      "Here are the text pairs:\n",
      "\n",
      "1. Premise: A man dressed all in white throws the first pitch at a baseball game .\n",
      "Hypothesis: A Senator starts a baseball game .\n",
      "\n",
      "2. Premise: A woman with dark hair and a red dress sits next to a little girl with blond-hair and a white dress while reading a book .\n",
      "Hypothesis: A tall person with hair\n",
      "\n",
      "3. Premise: A firefighter , in full uniform , looks off into the distance .\n",
      "Hypothesis: The firefighter is going to put out a fire .\n",
      "\n",
      "JSON output:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text pairs that contain contradiction inference relation. Finally, select all text pairs that contain neutral inference relation.\n",
      "If none of the text pairs satisfy a condition, write 'None.'\n",
      "If all the text pairs belong satisfy a condition, write 'All.'\n",
      "Otherwise, provide the index numbers of the text pairs that satisfy each condition.\n",
      "\n",
      "Output your responses in JSON format with three keys: 'entailment', 'contradiction', and 'neutral'.\n",
      "A formatted example output is provided below.\n",
      "{'entailment': [None/All or index numbers of text pairs that contain entailment inference relation], 'contradiction': [None/All or index numbers of text pairs that contain contradiction inference relation], 'neutral': [None/All or index numbers of text pairs that contain neutral inference relation]}\n",
      "\n",
      "Here are the text pairs:\n",
      "\n",
      "1. Premise: A man dressed all in white throws the first pitch at a baseball game .\n",
      "Hypothesis: A Senator starts a baseball game .\n",
      "\n",
      "2. Premise: A woman with dark hair and a red dress sits next to a little girl with blond-hair and a white dress while reading a book .\n",
      "Hypothesis: A tall person with hair\n",
      "\n",
      "3. Premise: A firefighter , in full uniform , looks off into the distance .\n",
      "Hypothesis: The firefighter is going to put out a fire .\n",
      "\n",
      "4. Premise: While some people look in the barn , others walk on the bridge and some are enjoying cooling off in the water by the beach .\n",
      "Hypothesis: Some people are outside .\n",
      "\n",
      "5. Premise: The room full of youths reacts emotionally as they spectate .\n",
      "Hypothesis: a room full of kids crying at a movie .\n",
      "\n",
      "JSON output:\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in dev[(dev[\"taskSize\"] <= 5) & (dev[\"taskIndex\"] == 1)].prompt:\n",
    "    print(p)\n",
    "    print(\"-\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskIndex</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>targetLabel</th>\n",
       "      <th>task</th>\n",
       "      <th>#shot</th>\n",
       "      <th>CoT</th>\n",
       "      <th>taskSize</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': {'None'}, 'entailment': {4}, 'neutral': {1, 2, 3, 5}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once_adjusted</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>After analyzing the text pairs, I found the following results:\\n\\n{'entailment': [1, 4], 'contradiction': [2], 'neutral': [3, 5]}\\n\\nHere's a brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': {'None'}, 'entailment': {4, 5}, 'neutral': {1, 2, 3}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once_adjusted</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>After analyzing the text pairs, I found the following results:\\n\\n{'entailment': [2, 3], 'contradiction': None, 'neutral': [1, 4, 5]}\\n\\nHere's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 10 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text...</td>\n",
       "      <td>{'contradiction': {9, 10}, 'entailment': {8, 4, 7}, 'neutral': {1, 2, 3, 5, 6}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once_adjusted</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>After analyzing the text pairs, I found the following results:\\n\\n{\\n\"entailment\": [1, 4, 7], \\n\"contradiction\": [2, 6, 9], \\n\"neutral\": [3, 5, 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Go over the 10 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text...</td>\n",
       "      <td>{'contradiction': {9}, 'entailment': {4, 5, 7}, 'neutral': {1, 2, 3, 6, 8, 10}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once_adjusted</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>After analyzing the text pairs, I found the following results:\\n\\n{'entailment': [2, 3, 5, 6, 7, 8, 10], 'contradiction': [1, 9], 'neutral': [4]}\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   taskIndex  \\\n",
       "0          1   \n",
       "1          2   \n",
       "2          1   \n",
       "3          2   \n",
       "\n",
       "                                                                                                                                                  prompt  \\\n",
       "0  Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "1  Go over the 5 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "2  Go over the 10 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text...   \n",
       "3  Go over the 10 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text...   \n",
       "\n",
       "                                                                            answer  \\\n",
       "0          {'contradiction': {'None'}, 'entailment': {4}, 'neutral': {1, 2, 3, 5}}   \n",
       "1          {'contradiction': {'None'}, 'entailment': {4, 5}, 'neutral': {1, 2, 3}}   \n",
       "2  {'contradiction': {9, 10}, 'entailment': {8, 4, 7}, 'neutral': {1, 2, 3, 5, 6}}   \n",
       "3  {'contradiction': {9}, 'entailment': {4, 5, 7}, 'neutral': {1, 2, 3, 6, 8, 10}}   \n",
       "\n",
       "  targetLabel                                      task  #shot    CoT  \\\n",
       "0          NA  index_selection_all_cat_at_once_adjusted      0  False   \n",
       "1          NA  index_selection_all_cat_at_once_adjusted      0  False   \n",
       "2          NA  index_selection_all_cat_at_once_adjusted      0  False   \n",
       "3          NA  index_selection_all_cat_at_once_adjusted      0  False   \n",
       "\n",
       "   taskSize  \\\n",
       "0         5   \n",
       "1         5   \n",
       "2        10   \n",
       "3        10   \n",
       "\n",
       "                                                                                                                                                   preds  \n",
       "0  After analyzing the text pairs, I found the following results:\\n\\n{'entailment': [1, 4], 'contradiction': [2], 'neutral': [3, 5]}\\n\\nHere's a brea...  \n",
       "1  After analyzing the text pairs, I found the following results:\\n\\n{'entailment': [2, 3], 'contradiction': None, 'neutral': [1, 4, 5]}\\n\\nHere's a ...  \n",
       "2  After analyzing the text pairs, I found the following results:\\n\\n{\\n\"entailment\": [1, 4, 7], \\n\"contradiction\": [2, 6, 9], \\n\"neutral\": [3, 5, 8,...  \n",
       "3  After analyzing the text pairs, I found the following results:\\n\\n{'entailment': [2, 3, 5, 6, 7, 8, 10], 'contradiction': [1, 9], 'neutral': [4]}\\...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-3-8b-chat-hf\"\n",
    "dev[\"preds\"] = dev.prompt.apply(lambda p: get_completion(p, model))\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read object from data/databases/text classification/SNLI.pkl\n"
     ]
    }
   ],
   "source": [
    "database = read_obj_from_pickle(f\"data/databases/text classification/{clf_task}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = []\n",
    "# num_instance = 100\n",
    "# taskSizes = [3, 5, 10, 20, 50]\n",
    "# for propmtMode in [\"zero-shot\"]:\n",
    "#     for task in tasks:\n",
    "\n",
    "#         if task == \"single_clf\":\n",
    "#             out.append(make_prompts_for_clf(database, task, \"test\", propmtMode))\n",
    "#             continue\n",
    "\n",
    "#         for taskSize in taskSizes:\n",
    "#             out.append(make_prompts_for_clf(database, task, \"test\", propmtMode, taskSize, attr=\"relationship\", \n",
    "#                                             label_attr_converter=None, num_instance=num_instance))\n",
    "\n",
    "# out = pd.concat(out)\n",
    "# out.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"results/text classification/\", exist_ok=True)\n",
    "# out.to_json(f\"results/text classification/{clf_task}.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = f\"results/text classification/{clf_task}.json\"\n",
    "out = [pd.read_json(fp, lines=True)]\n",
    "\n",
    "num_instance = 100\n",
    "taskSizes = [3, 5, 10, 20, 50]\n",
    "for propmtMode in [\"zero-shot\"]:\n",
    "    for taskSize in taskSizes:\n",
    "        out.append(make_prompts_for_clf(database, tasks[-1], \"test\", propmtMode, taskSize, attr=\"relationship\", \n",
    "                                        label_attr_converter=None, num_instance=num_instance))\n",
    "\n",
    "out = pd.concat(out)\n",
    "out.reset_index(drop=True, inplace=True)\n",
    "\n",
    "os.makedirs(\"results/text classification/\", exist_ok=True)\n",
    "out.to_json(f\"results/text classification/{clf_task}.json\", orient=\"records\", lines=True)                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index_selection_one_cat_a_time              1500\n",
       "index_selection_one_cat_a_time_json         1500\n",
       "single_clf                                  1000\n",
       "batch_clf                                    500\n",
       "index_selection_all_cat_at_once              500\n",
       "index_selection_all_cat_at_once_adjusted     500\n",
       "Name: task, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.task.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5500.000000\n",
       "mean      614.437818\n",
       "std       581.198469\n",
       "min        71.000000\n",
       "25%       229.000000\n",
       "50%       376.000000\n",
       "75%       807.000000\n",
       "max      2008.000000\n",
       "Name: prompt, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.prompt.apply(get_num_of_tokens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskIndex</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>targetLabel</th>\n",
       "      <th>task</th>\n",
       "      <th>#shot</th>\n",
       "      <th>CoT</th>\n",
       "      <th>taskSize</th>\n",
       "      <th>gpt-3.5-turbo-0125-completion</th>\n",
       "      <th>meta-llama/Llama-3-70b-chat-hf-completion</th>\n",
       "      <th>meta-llama/Llama-3-8b-chat-hf-completion</th>\n",
       "      <th>mistralai/Mixtral-8x7B-Instruct-v0.1-completion</th>\n",
       "      <th>gpt-4-turbo-2024-04-09-completion</th>\n",
       "      <th>lmsys/vicuna-13b-v1.5-completion</th>\n",
       "      <th>mistralai/Mistral-7B-Instruct-v0.2-completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Given the following premise and hypothesis, determine the inference relation between them. Respond with 'Entailment' if the hypothesis logically f...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NA</td>\n",
       "      <td>single_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Inference relation: Entailment</td>\n",
       "      <td>Entailment\\n\\nThe premise sets the scene for a dramatic and intense situation, where the matador is being attacked by a raging bull. The hypothesi...</td>\n",
       "      <td>Neutral. The hypothesis is not directly entailed or contradicted by the premise. The premise does not provide information about the bull's reason...</td>\n",
       "      <td>Inference relation: Neutral\\n\\nExplanation: The premise describes a scene where a matador is getting hit by a raging bull, specifying the attire o...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>Neutral\\n\\nThe premise describes an action taking place between a matador and a bull, while the hypothesis makes a judgment about the justifiabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1</td>\n",
       "      <td>Given the following 3 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...</td>\n",
       "      <td>[Contradiction, Contradiction, Contradiction]</td>\n",
       "      <td>NA</td>\n",
       "      <td>batch_clf</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1. Neutral\\n2. Neutral\\n3. Contradiction</td>\n",
       "      <td>Here are the inference relations for each pair:\\n\\n1. Premise: This church choir sings to the masses as they sing joyous songs from the book at a ...</td>\n",
       "      <td>Here are the inference relations for each pair:\\n\\n1. Premise: This church choir sings to the masses as they sing joyous songs from the book at a ...</td>\n",
       "      <td>1. Neutral - The hypothesis of a choir singing at a baseball game is not directly related to the premise about a church choir singing joyous song...</td>\n",
       "      <td>1. Neutral - The premise describes a choir singing at a church, while the hypothesis mentions a choir singing at a baseball game. These are differ...</td>\n",
       "      <td>1. Entailment\\n2. Contradiction\\n3. Contradiction</td>\n",
       "      <td>1. Neutral: The premise is about a church choir singing to the masses, while the hypothesis is about a choir singing at a baseball game. These tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>[All]</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "      <td>2</td>\n",
       "      <td>After analyzing the text pairs, I found that:\\n\\n* Text pair 1: The premise describes a church choir singing at a church, while the hypothesis des...</td>\n",
       "      <td>1\\n3</td>\n",
       "      <td>1\\n2</td>\n",
       "      <td>None.</td>\n",
       "      <td>1. Index number: 1.\\n\\nExplanation: The premise describes a church choir singing joyous songs to the masses at a church. The hypothesis describes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "      <td>None.</td>\n",
       "      <td>After analyzing the text pairs, I found that:\\n\\n* Text pair 1 does not contain an entailment inference relation. The premise describes a church c...</td>\n",
       "      <td>None.\\n\\nNone of the text pairs have an entailment relationship between the premise and the hypothesis. In each case, the hypothesis goes beyond ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None.</td>\n",
       "      <td>None.\\n\\nExplanation:\\n\\n1. The premise describes a choir singing at a church, while the hypothesis describes a choir singing at a baseball game....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>index_selection_one_cat_a_time</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>None.</td>\n",
       "      <td>2.\\n\\nThe inference relation between the premise and the hypothesis is neutral in text pair 2, as the premise describes a woman preparing for dinn...</td>\n",
       "      <td>After analyzing the text pairs, I found that the inference relation between the premise and the hypothesis is neutral in the following index numbe...</td>\n",
       "      <td>None.\\n\\nIn the first text pair, the premise describes the church choir singing in a church, while the hypothesis describes a choir singing at a ...</td>\n",
       "      <td>1\\n2\\n3</td>\n",
       "      <td>None.</td>\n",
       "      <td>None.\\n\\nThe inference relations in all three text pairs are not neutral. In the first text pair, there is no inference relation as the premise a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': ['All'], 'entailment': ['None'], 'neutral': ['None']}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        1,\\n        2\\n    ],\\n    \"neutral\": [\\n        None\\n    ]\\n}</td>\n",
       "      <td>Here is the output in JSON format:\\n\\n{'entailment': [], 'contradiction': [2], 'neutral': [1, 3]}\\n\\nExplanation:\\n\\n* There are no text pairs tha...</td>\n",
       "      <td>Here is the output in JSON format:\\n\\n{\\n\"entailment\": [1],\\n\"contradiction\": [2],\\n\"neutral\": [3]\\n}\\n\\nExplanation:\\n\\n* Index 1 contains entail...</td>\n",
       "      <td>{\\n'entailment': [None],\\n'contradiction': [1, 2],\\n'neutral': [3]\\n}</td>\n",
       "      <td>```json\\n{\\n  \"entailment\": \"None\",\\n  \"contradiction\": [1, 2, 3],\\n  \"neutral\": \"None\"\\n}\\n```</td>\n",
       "      <td>{\\n\"entailment\": [\\n\"1\",\\n\"3\"\\n],\\n\"contradiction\": [\\n\"2\"\\n],\\n\"neutral\": [\\n\"2\"\\n]}</td>\n",
       "      <td>{'entailment': [None], 'contradiction': [1, 2], 'neutral': [3]}\\n\\nExplanation:\\n\\n1. The hypothesis \"A choir singing at a baseball game\" is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>[All]</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>index_selection_one_cat_a_time_json</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{'contradiction': [1, 2, 3]}</td>\n",
       "      <td>None</td>\n",
       "      <td>Here is the output in JSON format:\\n\\n{\\n\"contradiction\": [1]\\n}\\n\\nExplanation:\\n\\n* Text pair 1: The premise describes a church choir singing at...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>index_selection_one_cat_a_time_json</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{'entailment': [None]}</td>\n",
       "      <td>None</td>\n",
       "      <td>Here is the output in JSON format:\\n\\n{\\n\"entailment\": [1]\\n}\\n\\nExplanation:\\n\\n* Text pair 1: The premise describes a church choir singing at a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>index_selection_one_cat_a_time_json</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{'neutral': [None]}</td>\n",
       "      <td>None</td>\n",
       "      <td>After analyzing the text pairs, I found that none of them contain a neutral inference relation. Therefore, the output is:\\n\\n{'neutral': 'None'}\\n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>1</td>\n",
       "      <td>Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...</td>\n",
       "      <td>{'contradiction': {'All'}, 'entailment': {'None'}, 'neutral': {'None'}}</td>\n",
       "      <td>NA</td>\n",
       "      <td>index_selection_all_cat_at_once_adjusted</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      taskIndex  \\\n",
       "0             1   \n",
       "1000          1   \n",
       "1500          1   \n",
       "1501          1   \n",
       "1502          1   \n",
       "3000          1   \n",
       "3500          1   \n",
       "3501          1   \n",
       "3502          1   \n",
       "5000          1   \n",
       "\n",
       "                                                                                                                                                     prompt  \\\n",
       "0     Given the following premise and hypothesis, determine the inference relation between them. Respond with 'Entailment' if the hypothesis logically f...   \n",
       "1000  Given the following 3 pairs of premises and hypotheses, determine the inference relation for each pair line by line. Respond with 'Entailment' if ...   \n",
       "1500  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "1501  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "1502  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "3000  Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "3500  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "3501  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "3502  Go over the 3 text pairs below and list the index numbers of the text pairs where the inference relation between the premise and the hypothesis is...   \n",
       "5000  Go over the 3 text pairs below. First, list the index numbers of the text pairs that contain entailment inference relation. Then, select all text ...   \n",
       "\n",
       "                                                                       answer  \\\n",
       "0                                                                     Neutral   \n",
       "1000                            [Contradiction, Contradiction, Contradiction]   \n",
       "1500                                                                    [All]   \n",
       "1501                                                                   [None]   \n",
       "1502                                                                   [None]   \n",
       "3000  {'contradiction': ['All'], 'entailment': ['None'], 'neutral': ['None']}   \n",
       "3500                                                                    [All]   \n",
       "3501                                                                   [None]   \n",
       "3502                                                                   [None]   \n",
       "5000  {'contradiction': {'All'}, 'entailment': {'None'}, 'neutral': {'None'}}   \n",
       "\n",
       "        targetLabel                                      task  #shot    CoT  \\\n",
       "0                NA                                single_clf      0  False   \n",
       "1000             NA                                 batch_clf      0  False   \n",
       "1500  Contradiction            index_selection_one_cat_a_time      0  False   \n",
       "1501     Entailment            index_selection_one_cat_a_time      0  False   \n",
       "1502        Neutral            index_selection_one_cat_a_time      0  False   \n",
       "3000             NA           index_selection_all_cat_at_once      0  False   \n",
       "3500  Contradiction       index_selection_one_cat_a_time_json      0  False   \n",
       "3501     Entailment       index_selection_one_cat_a_time_json      0  False   \n",
       "3502        Neutral       index_selection_one_cat_a_time_json      0  False   \n",
       "5000             NA  index_selection_all_cat_at_once_adjusted      0  False   \n",
       "\n",
       "      taskSize  \\\n",
       "0            1   \n",
       "1000         3   \n",
       "1500         3   \n",
       "1501         3   \n",
       "1502         3   \n",
       "3000         3   \n",
       "3500         3   \n",
       "3501         3   \n",
       "3502         3   \n",
       "5000         3   \n",
       "\n",
       "                                                                                                                   gpt-3.5-turbo-0125-completion  \\\n",
       "0                                                                                                                                     Entailment   \n",
       "1000                                                                                                    1. Neutral\\n2. Neutral\\n3. Contradiction   \n",
       "1500                                                                                                                                       None.   \n",
       "1501                                                                                                                                       None.   \n",
       "1502                                                                                                                                       None.   \n",
       "3000  {\\n    \"entailment\": [\\n        3\\n    ],\\n    \"contradiction\": [\\n        1,\\n        2\\n    ],\\n    \"neutral\": [\\n        None\\n    ]\\n}   \n",
       "3500                                                                                                                {'contradiction': [1, 2, 3]}   \n",
       "3501                                                                                                                      {'entailment': [None]}   \n",
       "3502                                                                                                                         {'neutral': [None]}   \n",
       "5000                                                                                                                                         NaN   \n",
       "\n",
       "                                                                                                                  meta-llama/Llama-3-70b-chat-hf-completion  \\\n",
       "0                                                                                                                            Inference relation: Entailment   \n",
       "1000  Here are the inference relations for each pair:\\n\\n1. Premise: This church choir sings to the masses as they sing joyous songs from the book at a ...   \n",
       "1500                                                                                                                                                      2   \n",
       "1501                                                                                                                                                  None.   \n",
       "1502  2.\\n\\nThe inference relation between the premise and the hypothesis is neutral in text pair 2, as the premise describes a woman preparing for dinn...   \n",
       "3000  Here is the output in JSON format:\\n\\n{'entailment': [], 'contradiction': [2], 'neutral': [1, 3]}\\n\\nExplanation:\\n\\n* There are no text pairs tha...   \n",
       "3500                                                                                                                                                   None   \n",
       "3501                                                                                                                                                   None   \n",
       "3502                                                                                                                                                   None   \n",
       "5000                                                                                                                                                    NaN   \n",
       "\n",
       "                                                                                                                   meta-llama/Llama-3-8b-chat-hf-completion  \\\n",
       "0     Entailment\\n\\nThe premise sets the scene for a dramatic and intense situation, where the matador is being attacked by a raging bull. The hypothesi...   \n",
       "1000  Here are the inference relations for each pair:\\n\\n1. Premise: This church choir sings to the masses as they sing joyous songs from the book at a ...   \n",
       "1500  After analyzing the text pairs, I found that:\\n\\n* Text pair 1: The premise describes a church choir singing at a church, while the hypothesis des...   \n",
       "1501  After analyzing the text pairs, I found that:\\n\\n* Text pair 1 does not contain an entailment inference relation. The premise describes a church c...   \n",
       "1502  After analyzing the text pairs, I found that the inference relation between the premise and the hypothesis is neutral in the following index numbe...   \n",
       "3000  Here is the output in JSON format:\\n\\n{\\n\"entailment\": [1],\\n\"contradiction\": [2],\\n\"neutral\": [3]\\n}\\n\\nExplanation:\\n\\n* Index 1 contains entail...   \n",
       "3500  Here is the output in JSON format:\\n\\n{\\n\"contradiction\": [1]\\n}\\n\\nExplanation:\\n\\n* Text pair 1: The premise describes a church choir singing at...   \n",
       "3501  Here is the output in JSON format:\\n\\n{\\n\"entailment\": [1]\\n}\\n\\nExplanation:\\n\\n* Text pair 1: The premise describes a church choir singing at a ...   \n",
       "3502  After analyzing the text pairs, I found that none of them contain a neutral inference relation. Therefore, the output is:\\n\\n{'neutral': 'None'}\\n...   \n",
       "5000                                                                                                                                                    NaN   \n",
       "\n",
       "                                                                                                            mistralai/Mixtral-8x7B-Instruct-v0.1-completion  \\\n",
       "0      Neutral. The hypothesis is not directly entailed or contradicted by the premise. The premise does not provide information about the bull's reason...   \n",
       "1000   1. Neutral - The hypothesis of a choir singing at a baseball game is not directly related to the premise about a church choir singing joyous song...   \n",
       "1500                                                                                                                                                   1\\n3   \n",
       "1501   None.\\n\\nNone of the text pairs have an entailment relationship between the premise and the hypothesis. In each case, the hypothesis goes beyond ...   \n",
       "1502   None.\\n\\nIn the first text pair, the premise describes the church choir singing in a church, while the hypothesis describes a choir singing at a ...   \n",
       "3000                                                                                  {\\n'entailment': [None],\\n'contradiction': [1, 2],\\n'neutral': [3]\\n}   \n",
       "3500                                                                                                                                                   None   \n",
       "3501                                                                                                                                                   None   \n",
       "3502                                                                                                                                                   None   \n",
       "5000                                                                                                                                                    NaN   \n",
       "\n",
       "                                                                                                                          gpt-4-turbo-2024-04-09-completion  \\\n",
       "0     Inference relation: Neutral\\n\\nExplanation: The premise describes a scene where a matador is getting hit by a raging bull, specifying the attire o...   \n",
       "1000  1. Neutral - The premise describes a choir singing at a church, while the hypothesis mentions a choir singing at a baseball game. These are differ...   \n",
       "1500                                                                                                                                                   1\\n2   \n",
       "1501                                                                                                                                                   None   \n",
       "1502                                                                                                                                                1\\n2\\n3   \n",
       "3000                                                        ```json\\n{\\n  \"entailment\": \"None\",\\n  \"contradiction\": [1, 2, 3],\\n  \"neutral\": \"None\"\\n}\\n```   \n",
       "3500                                                                                                                                                   None   \n",
       "3501                                                                                                                                                   None   \n",
       "3502                                                                                                                                                   None   \n",
       "5000                                                                                                                                                    NaN   \n",
       "\n",
       "                                                            lmsys/vicuna-13b-v1.5-completion  \\\n",
       "0                                                                                 Entailment   \n",
       "1000                                       1. Entailment\\n2. Contradiction\\n3. Contradiction   \n",
       "1500                                                                                   None.   \n",
       "1501                                                                                   None.   \n",
       "1502                                                                                   None.   \n",
       "3000   {\\n\"entailment\": [\\n\"1\",\\n\"3\"\\n],\\n\"contradiction\": [\\n\"2\"\\n],\\n\"neutral\": [\\n\"2\"\\n]}   \n",
       "3500                                                                                    None   \n",
       "3501                                                                                    None   \n",
       "3502                                                                                    None   \n",
       "5000                                                                                     NaN   \n",
       "\n",
       "                                                                                                              mistralai/Mistral-7B-Instruct-v0.2-completion  \n",
       "0      Neutral\\n\\nThe premise describes an action taking place between a matador and a bull, while the hypothesis makes a judgment about the justifiabil...  \n",
       "1000   1. Neutral: The premise is about a church choir singing to the masses, while the hypothesis is about a choir singing at a baseball game. These tw...  \n",
       "1500   1. Index number: 1.\\n\\nExplanation: The premise describes a church choir singing joyous songs to the masses at a church. The hypothesis describes...  \n",
       "1501   None.\\n\\nExplanation:\\n\\n1. The premise describes a choir singing at a church, while the hypothesis describes a choir singing at a baseball game....  \n",
       "1502   None.\\n\\nThe inference relations in all three text pairs are not neutral. In the first text pair, there is no inference relation as the premise a...  \n",
       "3000   {'entailment': [None], 'contradiction': [1, 2], 'neutral': [3]}\\n\\nExplanation:\\n\\n1. The hypothesis \"A choir singing at a baseball game\" is not ...  \n",
       "3500                                                                                                                                                   None  \n",
       "3501                                                                                                                                                   None  \n",
       "3502                                                                                                                                                   None  \n",
       "5000                                                                                                                                                    NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = out.copy()[(out.taskIndex == 1) & (out.taskSize <= 3)]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out[\"lmsys/vicuna-13b-v1.5-completion\"].str.contains(\"TOO_\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
